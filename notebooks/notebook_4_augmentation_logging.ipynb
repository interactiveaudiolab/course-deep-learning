{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "76d05231-77c8-4d94-a445-0748a6033e48",
      "metadata": {
        "id": "76d05231-77c8-4d94-a445-0748a6033e48"
      },
      "source": [
        "# Notebook 4: Data Augmentation and Logging\n",
        "\n",
        "In this notebook, we'll expand our training loop for image classification to include __data augmentation__. We'll also use PyTorch's built-in __logging__ tools to monitor our network's progress as it trains.\n",
        "\n",
        "The notebook is broken up as follows:\n",
        "\n",
        "  1. [Setup](#setup)  \n",
        "  2. [Neural Networks for Image Recognition](#review)\n",
        "  3. [Data Augmentation](#augmentation)  \n",
        "  4. [Logging](#logging)  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2df0ea70-8b9e-4c8d-88f4-b8b947e24a47",
      "metadata": {
        "id": "2df0ea70-8b9e-4c8d-88f4-b8b947e24a47",
        "tags": []
      },
      "source": [
        "## __1.__ <a name=\"setup\">Setup</a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08ffed19-bf0e-4b4f-86e5-c13456ded4fa",
      "metadata": {
        "id": "08ffed19-bf0e-4b4f-86e5-c13456ded4fa"
      },
      "source": [
        "Make sure the needed packages are installed and utility code is in the right place."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7593208-6c33-463f-82d7-6e411696f76e",
      "metadata": {
        "id": "d7593208-6c33-463f-82d7-6e411696f76e"
      },
      "outputs": [],
      "source": [
        "# helper code from the course repository\n",
        "!git clone https://github.com/interactiveaudiolab/course-deep-learning.git\n",
        "# install common pacakges used for deep learning\n",
        "!cd course-deep-learning/ && pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70c1cadb-a5d7-4cec-8ef7-04253a7036ba",
      "metadata": {
        "id": "70c1cadb-a5d7-4cec-8ef7-04253a7036ba"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline\n",
        "%cd course-deep-learning/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4bf3ea7-458d-46cb-811f-e3607796845e",
      "metadata": {
        "id": "d4bf3ea7-458d-46cb-811f-e3607796845e"
      },
      "source": [
        "## __2.__ <a name=\"review\">Neural Networks for Image Recognition</a>\n",
        "\n",
        "In the previous notebook, we designed and trained a neural network to perform digit recognition on the MNIST dataset. In this notebook, we'll also consider a __convolutional neural network__ for the same task. Recall that convolutional networks use weight __kernels__ to capture correlations between neighboring coordinates. We can wrap the application of these kernels into a \"layer\" in the same way we do for weight-input dot products in a multilayer perceptron.\n",
        "\n",
        "In PyTorch, we can define a two-dimensional convolutional layer as follows:\n",
        "\n",
        "```\n",
        "conv_layer = nn.Conv2d(\n",
        "  in_channels,\n",
        "  out_channels,\n",
        "  kernel_size,\n",
        "  stride\n",
        ")\n",
        "```\n",
        "Some things to keep in mind:\n",
        "* `in_channels` refers to the number of channels in the input. In our case, because MNIST images are grayscale (1 channel), this value will be 1 for our first layer. \n",
        "* `kernel_size` can be either a tuple specifying `(kernel_height, kernel_width)` or an integer, in which case both the kernel height and width will be set to this value. Each kernel in the layer will have dimension `(in_channels, kernel_height, kernel_width)`, and will produce a single-channel feature map when applied to the input. Thus, `out_channels` refers to both the number of channels (feature maps) in the output and the number of convolutional kernels applied in the layer. \n",
        "* `stride` refers to the hop size when applying kernels, and can be either a tuple (specifying vertical and horizontal hop sizes) or an integer (in which case the same value will be used for both). \n",
        "* For an overview of more options, see the official [PyTorch documentation](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html).\n",
        "\n",
        "In addition to convolution, we'll experiment with two additional types of layers:\n",
        "* __Dropout__ randomly zeros elements of an input tensor with a given probability, ensuring that the network learns more robust and general features. In order to apply dropout at training time but _not_ at inference time, we can call `.train()` and `.eval()` on our network as usual; these will automatically set the behavior of any dropout layers in the model. For more details, see the [PyTorch documentation](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html).\n",
        "* __Max-Pooling__ can be thought of as a convolutional layer with `out_channels=in_channels`, but with the kernel dot-product operation replaced by a maximum. This can be used to \"pool\" or compress the spatial (height/width) dimensions of tensors as they pass through the network. For more details, see the [PyTorch documentation](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39b94f9f-d4a2-469b-a2c9-3c2bf9fb02ea",
      "metadata": {
        "id": "39b94f9f-d4a2-469b-a2c9-3c2bf9fb02ea"
      },
      "source": [
        "#### Model Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3da2571-1c64-4d01-82b4-500a0bcb39f4",
      "metadata": {
        "id": "d3da2571-1c64-4d01-82b4-500a0bcb39f4"
      },
      "outputs": [],
      "source": [
        "class LinearNetwork(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    \"\"\"The multi-layer perceptron from our previous notebook\"\"\"\n",
        "    super().__init__()\n",
        "\n",
        "    # MNIST images are (1, 28, 28) (channels, width, height)\n",
        "    self.layer_1 = nn.Linear(28*28, 1024)\n",
        "    self.layer_2 = nn.Linear(1024, 10)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    batch_size, channels, width, height = x.size()\n",
        "    x = x.view(batch_size, -1)  # create an array of flattened images with dimension (batch_size, num_pixels)\n",
        "\n",
        "    # this time, we'll use the ReLU nonlinearity at each layer  \n",
        "    x = self.relu(self.layer_1(x))\n",
        "    x = self.layer_2(x)  # we'll avoid \"squashing\" our final outputs by omitting the sigmoid\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "class ConvNetwork(nn.Module):\n",
        "    \"\"\"\n",
        "    A simple convolutional neural network for image classification.\n",
        "    From https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "      super().__init__()\n",
        "\n",
        "      # convolutional layers\n",
        "      self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "      self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "\n",
        "      # just like in our fully-connected network, we'll use ReLU activations\n",
        "      self.relu = nn.ReLU()\n",
        "\n",
        "      # random dropout with two different \"strengths\"\n",
        "      self.dropout1 = nn.Dropout(0.25)  # we pass the dropout probability\n",
        "      self.dropout2 = nn.Dropout(0.5)\n",
        "\n",
        "      # max-pooling\n",
        "      self.pool = nn.MaxPool2d(4)\n",
        "\n",
        "      # a final fully-connected network to map our learned convolutional\n",
        "      # features to class predictions\n",
        "      self.fc1 = nn.Linear(64*6*6, 128)\n",
        "      self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "      # inputs are expected to have shape (batch_size, 1, 28, 28)\n",
        "      x = self.conv1(x)\n",
        "      x = self.relu(x)\n",
        "\n",
        "      # out first convolutional layer reshapes inputs to (batch_size, 32, 26, 26)\n",
        "      x = self.conv2(x)\n",
        "      x = self.relu(x)\n",
        "\n",
        "      # our second convolutional layer reshapes inputs to (batch_size, 64, 24, 24)\n",
        "      x = self.pool(x)\n",
        "      x = self.dropout1(x)\n",
        "\n",
        "      # our pooling layer reduces inputs to (batch_size, 64, 6, 6)\n",
        "      x = torch.flatten(x, 1)\n",
        "\n",
        "      # we \"flatten\" inputs to (batch_size, 64 * 6 * 6) before passing to a \n",
        "      # small fully-connected network\n",
        "      x = self.fc1(x)\n",
        "      x = self.relu(x)\n",
        "      x = self.dropout2(x)\n",
        "      x = self.fc2(x)\n",
        "\n",
        "      # our final outputs are vectors of class scores, with shape (batch_size, 10)\n",
        "      return x\n",
        "\n",
        "\n",
        "def param_count(m: nn.Module):\n",
        "  \"\"\"Count the number of trainable parameters (weights) in a model\"\"\"\n",
        "  return sum([p.shape.numel() for p in m.parameters() if p.requires_grad])\n",
        "\n",
        "\n",
        "model1 = LinearNetwork()\n",
        "model2 = ConvNetwork()\n",
        "\n",
        "params1 = param_count(model1)\n",
        "params2 = param_count(model2)\n",
        "\n",
        "print(f'Parameters in fully-connected network: {params1}')\n",
        "print(f'Parameters in convolutional network: {params2}')\n",
        "print(f'The convolutional network has {params2/params1 :0.2f}x as many parameters')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "801d2928-7e46-4fba-8940-1240da5bf879",
      "metadata": {
        "id": "801d2928-7e46-4fba-8940-1240da5bf879"
      },
      "source": [
        "#### Training Loop\n",
        "\n",
        "Next, we'll slightly modify our training loop to allow for different models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c72e3a3a-4d41-4931-90ff-1ae9cfecbe91",
      "metadata": {
        "id": "c72e3a3a-4d41-4931-90ff-1ae9cfecbe91"
      },
      "outputs": [],
      "source": [
        "def training_loop(save_path, epochs, batch_size, device=\"cpu\", use_conv=False):\n",
        "    \"\"\"\n",
        "    Train a neural network model for digit recognition on the MNIST dataset.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    save_path (str):  path/filename for model checkpoint, e.g. 'my_model.pt'\n",
        "    \n",
        "    epochs (int):     number of iterations through the whole dataset for training\n",
        "    \n",
        "    batch_size (int): size of a single batch of inputs\n",
        "    \n",
        "    device (str):     device on which tensors are placed; should be 'cpu' or 'cuda'. \n",
        "\n",
        "    use_conv (bool):  if True, use ConvNetwork; else, use LinearNetwork.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    model (nn.Module): final trained model\n",
        "    \n",
        "    save_path (str):   path/filename for model checkpoint, so that we can load our model\n",
        "                       later to test on unseen data\n",
        "    \n",
        "    device (str):      the device on which we carried out training, so we can match it\n",
        "                       when we test the final model on unseen data later\n",
        "    \"\"\"\n",
        "\n",
        "    # initialize model\n",
        "    if use_conv:\n",
        "      model = ConvNetwork()\n",
        "      print('Training convolutional neural network...')\n",
        "    else:\n",
        "      model = LinearNetwork()\n",
        "      print('Training fully-connected neural network...')\n",
        "\n",
        "    print(f'Parameters in model: {param_count(model)}')\n",
        "    model.to(device)\n",
        "\n",
        "    # initialize an optimizer to update our model's parameters during training\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "    # optimizer = torch.optim.Adadelta(model.parameters(), lr=1.0)\n",
        "\n",
        "    # make a new directory in which to download the MNIST dataset\n",
        "    data_dir = \"./data/\"\n",
        "    \n",
        "    # initialize a Transform object to prepare our data\n",
        "    transform = torchvision.transforms.Compose([\n",
        "        torchvision.transforms.ToTensor(),\n",
        "        lambda x: x>0,\n",
        "        lambda x: x.float(),\n",
        "    ])\n",
        "\n",
        "    # load MNIST \"test\" dataset from disk\n",
        "    mnist_test = datasets.MNIST(data_dir, train=False, download=True, transform=transform)\n",
        "\n",
        "    # load MNIST \"train\" dataset from disk and set aside a portion for validation\n",
        "    mnist_train_full = datasets.MNIST(data_dir, train=True, download=True, transform=transform)\n",
        "    mnist_train, mnist_val = torch.utils.data.random_split(mnist_train_full, [55000, 5000])\n",
        "\n",
        "    # initialize a DataLoader object for each dataset\n",
        "    train_dataloader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
        "    val_dataloader = torch.utils.data.DataLoader(mnist_val, batch_size=batch_size, shuffle=False)\n",
        "    test_dataloader = torch.utils.data.DataLoader(mnist_test, batch_size=1, shuffle=False)\n",
        "\n",
        "    # a PyTorch categorical cross-entropy loss object\n",
        "    loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    # time training process\n",
        "    st = time.time()\n",
        "\n",
        "    # keep track of best validation accuracy; if improved upon, save checkpoint\n",
        "    best_acc = 0.0\n",
        "\n",
        "    # time to start training!\n",
        "    for epoch_idx, epoch in enumerate(range(epochs)):\n",
        "\n",
        "        # loop through the entire dataset once per epoch\n",
        "        train_loss = 0.0\n",
        "        train_acc = 0.0\n",
        "        train_total = 0\n",
        "        model.train()\n",
        "        for batch_idx, batch in enumerate(train_dataloader):\n",
        "\n",
        "            # clear gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # unpack data and labels\n",
        "            x, y = batch\n",
        "            x = x.to(device)  # we'll cover this in the next section!\n",
        "            y = y.to(device)  # we'll cover this in the next section!\n",
        "\n",
        "            # generate predictions and compute loss\n",
        "            output = model(x)  # (batch_size, 10)\n",
        "            loss = loss_fn(output, y)\n",
        "\n",
        "            # compute accuracy\n",
        "            preds = output.argmax(dim=1)\n",
        "            acc = preds.eq(y).sum().item()/len(y)\n",
        "\n",
        "            # compute gradients and update model parameters\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # update statistics\n",
        "            train_loss += (loss * len(x))\n",
        "            train_acc += (acc * len(x))\n",
        "            train_total += len(x)\n",
        "\n",
        "        train_loss /= train_total\n",
        "        train_acc /= train_total\n",
        "\n",
        "        # perform validation once per epoch\n",
        "        val_loss = 0.0\n",
        "        val_acc = 0.0\n",
        "        val_total = 0\n",
        "        model.eval()\n",
        "        for batch_idx, batch in enumerate(val_dataloader):\n",
        "\n",
        "            # don't compute gradients during validation\n",
        "            with torch.no_grad():\n",
        "\n",
        "                # unpack data and labels\n",
        "                x, y = batch\n",
        "                x = x.to(device)  # we'll cover this in the next section!\n",
        "                y = y.to(device)  # we'll cover this in the next section!\n",
        "\n",
        "                # generate predictions and compute loss\n",
        "                output = model(x)\n",
        "                loss = loss_fn(output, y)\n",
        "\n",
        "                # compute accuracy\n",
        "                preds = output.argmax(dim=1)\n",
        "                acc = preds.eq(y).sum().item()/len(y)\n",
        "\n",
        "                # update statistics\n",
        "                val_loss += (loss * len(x))\n",
        "                val_acc += (acc * len(x))\n",
        "                val_total += len(x)\n",
        "\n",
        "        val_loss /= val_total\n",
        "        val_acc /= val_total\n",
        "        print(f\"Epoch {epoch_idx + 1}: val loss {val_loss :0.3f}, val acc {val_acc :0.3f}, train loss {train_loss :0.3f}, train acc {train_acc :0.3f}\")\n",
        "\n",
        "        if val_acc > best_acc:\n",
        "            print(f\"New best accuracy {val_acc : 0.3f} (old {best_acc : 0.3f}); saving model weights to {save_path}\")\n",
        "            best_acc = val_acc\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "\n",
        "    print(f\"Total training time (s): {time.time() - st :0.3f}\")\n",
        "    \n",
        "    return model, save_path, device\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9367db63-7e64-4ac8-9216-be729f9c15bf",
      "metadata": {
        "id": "9367db63-7e64-4ac8-9216-be729f9c15bf"
      },
      "source": [
        "#### Run It!\n",
        "\n",
        "Finally, we can compare our convolutional and fully-connected models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9418055-6cf2-43e9-8d6f-5c6e50735f09",
      "metadata": {
        "id": "b9418055-6cf2-43e9-8d6f-5c6e50735f09"
      },
      "outputs": [],
      "source": [
        "# train a convolutional neural network\n",
        "conv_model, conv_path, device = training_loop(\n",
        "    save_path=\"mnist_cnn.pt\", \n",
        "    epochs=20, \n",
        "    batch_size=60, \n",
        "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "    use_conv=True\n",
        ")\n",
        "\n",
        "# train a fully-connected neural network\n",
        "lin_model, lin_path, device = training_loop(\n",
        "    save_path=\"mnist_fc.pt\", \n",
        "    epochs=20, \n",
        "    batch_size=60, \n",
        "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "    use_conv=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our convolutional network is able to achieve a classification accuracy __~4%__ higher than our fully-connected network, with less than half the parameters!"
      ],
      "metadata": {
        "id": "ZMAkPGvztiBU"
      },
      "id": "ZMAkPGvztiBU"
    },
    {
      "cell_type": "markdown",
      "id": "cfbb51e2-bcdc-435c-aea8-f2efa94df648",
      "metadata": {
        "id": "cfbb51e2-bcdc-435c-aea8-f2efa94df648",
        "outputId": "9348bd86-e439-48de-e0a3-f9935787cf8e",
        "tags": []
      },
      "source": [
        "## __3.__ <a name=\"augmentation\">Data Augmentation</a>\n",
        "\n",
        "We've got a pretty accurate model, but there are plenty of deep learning tricks we can use to squeeze some extra performance. One common practice is __data augmentation__, in which random transformations are applied to inputs during training. This helps in two ways:\n",
        "* Often, datasets are relatively small and imperfectly represent the popluation from which they are sampled. Data augmentation effectively expands the size of the dataset through sampling additional randomized variations of each instance.\n",
        "* We typically want to train a model that is __robust__ against common real-world transformations of its inputs -- that is, a model whose predictions are __invariant__ under these transformations. Data augmentation exposes our model to a chosen set of transformations during training so that it can learn to \"see past\" them.\n",
        "\n",
        "TorchVision provides a number of `Transform` objects designed to perform data augmentation, making it easy to apply transformations automatically when data is fetched from a `Dataset` object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3663caa-62a9-4ecd-803d-b2bd36c6a231",
      "metadata": {
        "id": "f3663caa-62a9-4ecd-803d-b2bd36c6a231"
      },
      "outputs": [],
      "source": [
        "# directory for MNIST dataset\n",
        "data_dir = \"./data/\"\n",
        "\n",
        "# initialize a Transform object to prepare our data\n",
        "transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    lambda x: x>0,\n",
        "    lambda x: x.float(),\n",
        "])\n",
        "\n",
        "# load MNIST \"train\" dataset from disk\n",
        "mnist_train = datasets.MNIST(data_dir, train=False, download=True, transform=transform)\n",
        "\n",
        "# fetch an image from the MNIST dataset\n",
        "example_img, example_label = mnist_train[300]\n",
        "plt.imshow(example_img.squeeze(), cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "# perform a random affine transformation of an input (rotation, translation, shear)\n",
        "affine_aug = torchvision.transforms.RandomAffine(degrees=(-30, 30), translate=(0.25, 0.25), shear=(-45, 45))\n",
        "augmented = affine_aug(example_img)\n",
        "plt.imshow(augmented.squeeze(), cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9650113-cdf9-4b1f-a39e-5863287d0ca2",
      "metadata": {
        "id": "d9650113-cdf9-4b1f-a39e-5863287d0ca2",
        "outputId": "9348bd86-e439-48de-e0a3-f9935787cf8e"
      },
      "source": [
        "Because we're effectively increasing the size of the dataset, and due to the computation required to perform each transformation, training with data augmentation may take more time (as measured in both walltime and iterations). It's also worth noting that augmentations are typically applied to the training data only. While we won't go into detail at the moment, feel free to try training with any of the [augmentations offered by TorchVision](https://pytorch.org/vision/stable/transforms.html). You can add augmentations to the training loop above by editing the `transfom` object:\n",
        "\n",
        "```\n",
        "# initialize a Transform object to prepare our data\n",
        "transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    lambda x: x>0,\n",
        "    lambda x: x.float(),\n",
        "    torchvision.transforms.RandomAffine(degrees=(-30, 30), translate=(0.25, 0.25), shear=(-45, 45))  # just append transforms!\n",
        "])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d616308-8574-43bb-a9b3-ea3b92f899e9",
      "metadata": {
        "id": "6d616308-8574-43bb-a9b3-ea3b92f899e9",
        "outputId": "9348bd86-e439-48de-e0a3-f9935787cf8e",
        "tags": []
      },
      "source": [
        "## __4.__ <a name=\"logging\">Logging</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f9fe057-59da-47a9-9ccf-ca9d96070ca1",
      "metadata": {
        "id": "7f9fe057-59da-47a9-9ccf-ca9d96070ca1",
        "outputId": "9348bd86-e439-48de-e0a3-f9935787cf8e"
      },
      "source": [
        "In our training loop, we print running summaries of our model's training performance in order to monitor its progress. This is somewhat clunky and limited - what if we want to plot accuracy in real time, visualize challenging instances, dynamically change what information is displayed, or document and compare across multiple training runs? All these tasks fall under the umbrella of __logging__, and once again, PyTorch provides utilities to simplify the process. We can use PyTorch's built-in TensorBoard support to configure and view training logs without the need for any external database or visualization software. To launch TensorBoard within the notebook, run the cell below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bfc97e7-86a5-41c7-941d-951dce68a654",
      "metadata": {
        "id": "4bfc97e7-86a5-41c7-941d-951dce68a654"
      },
      "outputs": [],
      "source": [
        "# here, we'll initialize TensorBoard. You should see an empty window in this cell, which will populate with\n",
        "# graphs as soon as we run our training code below.\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0a8b591-8607-437f-9380-2a99c3cf1e2d",
      "metadata": {
        "id": "b0a8b591-8607-437f-9380-2a99c3cf1e2d",
        "outputId": "b47b6db9-4f27-42f0-bb93-f497018aa513"
      },
      "source": [
        "Next, we'll re-write out training loop to log loss and accuracy values to TensorBoard rather than printing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7633848e-400c-4e8c-a73b-04b4244b2377",
      "metadata": {
        "id": "7633848e-400c-4e8c-a73b-04b4244b2377"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "from pathlib import Path\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# save all log data to a local directory\n",
        "run_dir = \"logs\"\n",
        "\n",
        "# timestamp the logs for each run so we can sort through them \n",
        "run_time = datetime.datetime.now().strftime(\"%I:%M%p on %B %d, %Y\")\n",
        "\n",
        "# initialize a SummaryWriter object to handle all logging actions\n",
        "logger = SummaryWriter(log_dir=Path(run_dir) / run_time)\n",
        "\n",
        "def training_loop(save_path, \n",
        "                  epochs, \n",
        "                  batch_size, \n",
        "                  device=\"cpu\", \n",
        "                  use_conv=False,\n",
        "                  logger=None\n",
        "                  ):\n",
        "    \"\"\"\n",
        "    Train a neural network model for digit recognition on the MNIST dataset.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    save_path (str):        path/filename for model checkpoint, e.g. 'my_model.pt'\n",
        "    \n",
        "    epochs (int):           number of iterations through the whole dataset for training\n",
        "    \n",
        "    batch_size (int):       size of a single batch of inputs\n",
        "    \n",
        "    device (str):           device on which tensors are placed; should be 'cpu' or 'cuda'. \n",
        "\n",
        "    use_conv (bool):        if True, use ConvNetwork; else, use LinearNetwork.\n",
        "\n",
        "    logger (SummaryWriter): a TensorBoard logger\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    model (nn.Module): final trained model\n",
        "    \n",
        "    save_path (str):   path/filename for model checkpoint, so that we can load our model\n",
        "                       later to test on unseen data\n",
        "    \n",
        "    device (str):      the device on which we carried out training, so we can match it\n",
        "                       when we test the final model on unseen data later\n",
        "    \"\"\"\n",
        "\n",
        "    # initialize model\n",
        "    if use_conv:\n",
        "      model = ConvNetwork()\n",
        "      print('Training convolutional neural network...')\n",
        "    else:\n",
        "      model = LinearNetwork()\n",
        "      print('Training fully-connected neural network...')\n",
        "\n",
        "    print(f'Parameters in model: {param_count(model)}')\n",
        "    model.to(device)\n",
        "\n",
        "    # initialize an optimizer to update our model's parameters during training\n",
        "    if use_conv:\n",
        "      optimizer = torch.optim.Adadelta(model.parameters(), lr=1.0)\n",
        "    else:\n",
        "      optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "    # make a new directory in which to download the MNIST dataset\n",
        "    data_dir = \"./data/\"\n",
        "    \n",
        "    # initialize a Transform object to prepare our data\n",
        "    transform = torchvision.transforms.Compose([\n",
        "        torchvision.transforms.ToTensor(),\n",
        "        lambda x: x>0,\n",
        "        lambda x: x.float(),\n",
        "    ])\n",
        "\n",
        "    # load MNIST \"test\" dataset from disk\n",
        "    mnist_test = datasets.MNIST(data_dir, train=False, download=True, transform=transform)\n",
        "\n",
        "    # load MNIST \"train\" dataset from disk and set aside a portion for validation\n",
        "    mnist_train_full = datasets.MNIST(data_dir, train=True, download=True, transform=transform)\n",
        "    mnist_train, mnist_val = torch.utils.data.random_split(mnist_train_full, [55000, 5000])\n",
        "\n",
        "    # initialize a DataLoader object for each dataset\n",
        "    train_dataloader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
        "    val_dataloader = torch.utils.data.DataLoader(mnist_val, batch_size=batch_size, shuffle=False)\n",
        "    test_dataloader = torch.utils.data.DataLoader(mnist_test, batch_size=1, shuffle=False)\n",
        "\n",
        "    # a PyTorch categorical cross-entropy loss object\n",
        "    loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    # time training process\n",
        "    st = time.time()\n",
        "\n",
        "    # keep track of best validation accuracy; if improved upon, save checkpoint\n",
        "    best_acc = 0.0\n",
        "\n",
        "    # time to start training!\n",
        "    for epoch_idx, epoch in enumerate(range(epochs)):\n",
        "\n",
        "        # loop through the entire dataset once per epoch\n",
        "        train_loss = 0.0\n",
        "        train_acc = 0.0\n",
        "        train_total = 0\n",
        "        model.train()\n",
        "        for batch_idx, batch in enumerate(train_dataloader):\n",
        "\n",
        "            # clear gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # unpack data and labels\n",
        "            x, y = batch\n",
        "            x = x.to(device)  # we'll cover this in the next section!\n",
        "            y = y.to(device)  # we'll cover this in the next section!\n",
        "\n",
        "            # generate predictions and compute loss\n",
        "            output = model(x)  # (batch_size, 10)\n",
        "            loss = loss_fn(output, y)\n",
        "\n",
        "            # compute accuracy\n",
        "            preds = output.argmax(dim=1)\n",
        "            acc = preds.eq(y).sum().item()/len(y)\n",
        "\n",
        "            # compute gradients and update model parameters\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # update statistics\n",
        "            train_loss += (loss * len(x))\n",
        "            train_acc += (acc * len(x))\n",
        "            train_total += len(x)\n",
        "\n",
        "        train_loss /= train_total\n",
        "        train_acc /= train_total\n",
        "\n",
        "        ########################################################################\n",
        "        # NEW: log to TensorBoard\n",
        "        ########################################################################\n",
        "\n",
        "        if logger is not None:\n",
        "          logger.add_scalar(\"train_loss\", train_loss, epoch_idx)\n",
        "          logger.add_scalar(\"train_acc\", train_acc, epoch_idx)\n",
        "\n",
        "        # perform validation once per epoch\n",
        "        val_loss = 0.0\n",
        "        val_acc = 0.0\n",
        "        val_total = 0\n",
        "        model.eval()\n",
        "        for batch_idx, batch in enumerate(val_dataloader):\n",
        "\n",
        "            # don't compute gradients during validation\n",
        "            with torch.no_grad():\n",
        "\n",
        "                # unpack data and labels\n",
        "                x, y = batch\n",
        "                x = x.to(device)  # we'll cover this in the next section!\n",
        "                y = y.to(device)  # we'll cover this in the next section!\n",
        "\n",
        "                # generate predictions and compute loss\n",
        "                output = model(x)\n",
        "                loss = loss_fn(output, y)\n",
        "\n",
        "                # compute accuracy\n",
        "                preds = output.argmax(dim=1)\n",
        "                acc = preds.eq(y).sum().item()/len(y)\n",
        "\n",
        "                # update statistics\n",
        "                val_loss += (loss * len(x))\n",
        "                val_acc += (acc * len(x))\n",
        "                val_total += len(x)\n",
        "\n",
        "        val_loss /= val_total\n",
        "        val_acc /= val_total\n",
        "\n",
        "        ########################################################################\n",
        "        # NEW: log to TensorBoard\n",
        "        ########################################################################\n",
        "        \n",
        "        if logger is not None:\n",
        "          logger.add_scalar(\"val_loss\", val_loss, epoch_idx)\n",
        "          logger.add_scalar(\"val_acc\", val_acc, epoch_idx)\n",
        "        \n",
        "        print(f\"Epoch {epoch_idx + 1}: val loss {val_loss :0.3f}, val acc {val_acc :0.3f}, train loss {train_loss :0.3f}, train acc {train_acc :0.3f}\")\n",
        "\n",
        "        if val_acc > best_acc:\n",
        "            print(f\"New best accuracy {val_acc : 0.3f} (old {best_acc : 0.3f}); saving model weights to {save_path}\")\n",
        "            best_acc = val_acc\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "\n",
        "    print(f\"Total training time (s): {time.time() - st :0.3f}\")\n",
        "    \n",
        "    return model, save_path, device\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb3c2f18-ff04-420c-a47c-16c1387bcae3",
      "metadata": {
        "id": "bb3c2f18-ff04-420c-a47c-16c1387bcae3"
      },
      "outputs": [],
      "source": [
        "# run our training loop\n",
        "model, save_path, device = training_loop(\n",
        "    save_path=\"mnist_review.pt\", \n",
        "    epochs=10, \n",
        "    batch_size=60, \n",
        "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "    use_conv=True,\n",
        "    logger=logger\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcb29bfa-c022-460d-92b2-706c50061272",
      "metadata": {
        "id": "dcb29bfa-c022-460d-92b2-706c50061272",
        "outputId": "9348bd86-e439-48de-e0a3-f9935787cf8e"
      },
      "source": [
        "We can also run TensorBoard from the terminal, in which case we can view the logs in a browser by navigating to the correct port on our `localhost`. In the example below, after running the command we would need to point our browser to `localhost:9999`\n",
        "\n",
        "```\n",
        "$ tensorboard --logdir /path/to/logging/directory/ --port 9999\n",
        "```\n",
        "\n",
        "If no port is given, TensorBoard will default to 6006. In fact, the logs from your experiment above should already be visible at `localhost:6006`. TensorBoard will continue serving on this port until the notebook kernel shuts down or you halt the terminal command (e.g. using `ctrl` + `c`), at which point you will not be able to view your logs until you re-start TensorBoard."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "course-deep-learning",
      "language": "python",
      "name": "course-deep-learning"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "name": "notebook_4_augmentation_logging (2).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}